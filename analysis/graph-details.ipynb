{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lucky-departure",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [8, 8]\n",
    "# use LaTeX fonts in the plot\n",
    "matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update({\n",
    "    \"pgf.texsystem\": \"pdflatex\",\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False,\n",
    "})\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-debut",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT = \"single\"\n",
    "EVAL_DIR = \"/home/felix/todo/algohol/single\"\n",
    "MLP_METHODS = [\"kmeans\", \"gonzalez\", \"merge\"]\n",
    "MLP_LEVELS = [[int(2 ** i)] for i in np.arange(9.0, 12.5, 1.0)]\n",
    "FAST_QUERY_METHODS = [\"pcrp\", \"pch\", \"prp\"]\n",
    "QUERY_METHODS = [\"normal\"] + FAST_QUERY_METHODS\n",
    "AREAS = [\"baden-wuerttemberg\"]\n",
    "print(MLP_METHODS, \"with\", MLP_LEVELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equivalent-cabinet",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-flavor",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_graph = pd.DataFrame()\n",
    "for area in AREAS:\n",
    "    for mlp_method in MLP_METHODS:\n",
    "        for level in MLP_LEVELS:\n",
    "            for query in QUERY_METHODS:\n",
    "                df_new = pd.read_json(EVAL_DIR + \"/\" + area + \"-\" + mlp_method + \"-\" +  \"_\".join(map(str, level)) + \"-\" + query + \"-info.json\", typ='series')\n",
    "                df_new = pd.DataFrame([df_new])\n",
    "                df_new[\"Area\"] = area\n",
    "                df_new[\"MLP_method\"] = mlp_method\n",
    "                df_new[\"Levels\"] = \"_\".join(map(str, level))\n",
    "                df_new[\"Query\"] = query\n",
    "                df_graph = pd.concat([df_graph, df_new], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert((df_graph.groupby([\"amount_edges\"]).size() == len(QUERY_METHODS)).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-contest",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_graph.groupby([\"MLP_method\", \"Levels\", \"Query\"])[\"amount_used_edges\"].first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-armenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_tex(float_number):\n",
    "#     exponent = np.floor(np.log10(float_number))\n",
    "    exponent = 6\n",
    "    mantissa = float_number/10**exponent\n",
    "    return \"${:0.1f}\\\\times10^{{{:}}}$\".format(float(mantissa), str(int(exponent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handy-preservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_graph[\"amount_used_edges\"] = pd.to_numeric(df_graph[\"amount_used_edges\"], downcast=\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-investigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table = pd.DataFrame()\n",
    "for area in AREAS:\n",
    "    dijkstra = df_graph[(df_graph.Query == \"normal\") & (df_graph.Area == area)][\"amount_used_edges\"].iloc[0]\n",
    "    print(\"original edge amount:\", dijkstra)\n",
    "    for query in FAST_QUERY_METHODS:\n",
    "        for mlp in MLP_METHODS:\n",
    "            line = dict()\n",
    "            for partitions in MLP_LEVELS:\n",
    "                tmp = df_graph[(df_graph.Area == area) & (df_graph.Query == query) & (df_graph.MLP_method == mlp) & (df_graph.Levels == \"_\".join(map(str, partitions)))]\n",
    "                line[partitions[0]] = tmp[\"amount_used_edges\"].values[0]\n",
    "            df_new = pd.DataFrame([line])\n",
    "            df_new[\"MLP_method\"] = mlp_title(mlp)\n",
    "            df_new[\"Query\"] = query.upper()\n",
    "            df_table = pd.concat([df_table, df_new], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-israel",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edges = df_table.groupby([\"Query\", \"MLP_method\"]).first()\n",
    "# latex = df_edges.to_latex(float_format=\"{:0.1f}\".format)\n",
    "latex = df_edges.to_latex(float_format=format_tex, escape=False)\n",
    "df_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-breathing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixup ugly latex code to have single line header\n",
    "latex_list = latex.splitlines()\n",
    "\n",
    "latex_list[0] = latex_list[0].replace('ll', 'll|', 1)\n",
    "\n",
    "partitions = latex_list[2]\n",
    "headers = latex_list[3].split(\"&\")\n",
    "headers = [headers[0], headers[1], \" \\multicolumn{\" + str(len(headers) - 2) + \"}{c}{amount of partitions} \\\\\\\\\"]\n",
    "\n",
    "latex_list[3] = partitions\n",
    "latex_list[2] = \"&\".join(headers)\n",
    "\n",
    "latex_list.insert(len(latex_list)-8, '\\midrule')\n",
    "latex_list.insert(len(latex_list)-5, '\\midrule')\n",
    "latex_new = '\\n'.join(latex_list)\n",
    "latex_new = latex_new.replace(\"MLP_method\", \"MLP-method\")\n",
    "with open(OUTPUT + \"-edges.tex\", \"w\") as latex_file:\n",
    "    latex_file.writelines(latex_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-belgium",
   "metadata": {},
   "source": [
    "# level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-tennis",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT = \"level\"\n",
    "EVAL_DIR = \"/home/felix/todo/algohol/level\"\n",
    "MLP_METHODS = [\"merge\"]\n",
    "MLP_LEVELS = [[int(2 ** i)] for i in np.arange(9.0, 11.5, 1.0)]\n",
    "MLP_LEVELS = MLP_LEVELS + [[int(2 ** i), 4] for i in np.arange(9.0, 11.5, 1.0)]\n",
    "MLP_LEVELS = MLP_LEVELS + [[int(2 ** i), 16] for i in np.arange(9.0, 11.5, 1.0)]\n",
    "MLP_LEVELS = MLP_LEVELS + [[int(2 ** i), 4, 4] for i in np.arange(9.0, 11.5, 1.0)]\n",
    "FAST_QUERY_METHODS = [\"pcrp\", \"pch\", \"prp\"]\n",
    "QUERY_METHODS = [\"normal\"] + FAST_QUERY_METHODS\n",
    "AREAS = [\"baden-wuerttemberg\"]\n",
    "print(MLP_METHODS, \"with\", MLP_LEVELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-bottom",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_graph = pd.DataFrame()\n",
    "for area in AREAS:\n",
    "    for mlp_method in MLP_METHODS:\n",
    "        for level in MLP_LEVELS:\n",
    "            for query in QUERY_METHODS:\n",
    "                df_new = pd.read_json(EVAL_DIR + \"/\" + area + \"-\" + mlp_method + \"-\" +  \"_\".join(map(str, level)) + \"-\" + query + \"-info.json\", typ='series')\n",
    "                df_new = pd.DataFrame([df_new])\n",
    "                df_new[\"Area\"] = area\n",
    "                df_new[\"MLP_method\"] = mlp_method\n",
    "                df_new[\"Levels\"] = \"_\".join(map(str, level))\n",
    "                df_new[\"Query\"] = query\n",
    "                df_graph = pd.concat([df_graph, df_new], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-spray",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert((df_graph.groupby([\"amount_edges\"]).size() == len(QUERY_METHODS)).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-birth",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_graph[\"amount_used_edges\"] = pd.to_numeric(df_graph[\"amount_used_edges\"], downcast=\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-courage",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table = pd.DataFrame()\n",
    "for area in AREAS:\n",
    "    dijkstra = df_graph[(df_graph.Query == \"normal\") & (df_graph.Area == area)][\"amount_used_edges\"].iloc[0]\n",
    "    print(\"original edge amount:\", dijkstra)\n",
    "    for mlp in MLP_METHODS:\n",
    "        for partitions in MLP_LEVELS:\n",
    "            line = dict()\n",
    "            for query in FAST_QUERY_METHODS:\n",
    "                tmp = df_graph[(df_graph.Area == area) & (df_graph.Query == query) & (df_graph.MLP_method == mlp) & (df_graph.Levels == \"_\".join(map(str, partitions)))]\n",
    "                line[query.upper()] = tmp[\"amount_used_edges\"].values[0]\n",
    "            df_new = pd.DataFrame([line])\n",
    "            df_new[\"partitions\"] = \"_\".join(map(str, partitions))\n",
    "            df_table = pd.concat([df_table, df_new], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-saint",
   "metadata": {},
   "outputs": [],
   "source": [
    "def special_hacky_sort(x):\n",
    "    splited = x.str.split(\"-\", expand=True)\n",
    "    return pd.DataFrame(splited).astype(float).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-physics",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table['partitions'] = df_table['partitions'].str.replace('_','-')\n",
    "df_edges = df_table.groupby(\"partitions\").first()\n",
    "df_edges = df_edges.sort_values(by=\"partitions\", key=special_hacky_sort)\n",
    "latex = df_edges.to_latex(float_format=format_tex, escape=False)\n",
    "df_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-decade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixup ugly latex code to have single line header\n",
    "latex_list = latex.splitlines()\n",
    "\n",
    "latex_list[0] = latex_list[0].replace('lr', 'l|r', 1)\n",
    "\n",
    "columns = latex_list[2].split(\"&\")\n",
    "indices = latex_list[3].split(\"&\")\n",
    "\n",
    "latex_list[2] = \" & \\multicolumn{\" + str(len(FAST_QUERY_METHODS)) + \"}{c}{Dijkstra-Query} \\\\\\\\\"\n",
    "\n",
    "latex_list[3] = \"&\".join(indices[:1] + columns[1:])\n",
    "\n",
    "\n",
    "latex_list.insert(len(latex_list)-10, '\\midrule')\n",
    "latex_list.insert(len(latex_list)-6, '\\midrule')\n",
    "latex_new = '\\n'.join(latex_list)\n",
    "\n",
    "with open(OUTPUT + \"-edges.tex\", \"w\") as latex_file:\n",
    "    latex_file.writelines(latex_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-nitrogen",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
