{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-pastor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import *\n",
    "import subprocess\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-nursery",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# simply put osm files into the data-dir (all will get evaluated)\n",
    "EVAL_DIR = \"/home/felix/todo/osm-tmp\"\n",
    "SRTM_DIR = \"/home/felix/todo/osm/srtm\"\n",
    "MLP_METHODS = [\"kmeans\", \"merge\", \"hop\"]\n",
    "# MLP_LAYERS = [[int(2 ** i)] for i in np.arange(8.0, 13.5, 0.5)]\n",
    "MLP_LAYERS = [[int(2 ** i)] for i in np.arange(8.0, 13.5, 1.0)]\n",
    "QUERY_METHODS = [\"normal\", \"bi\", \"crp\", \"pch\", \"prp\"]\n",
    "EVAL_FILE = os.path.join(EVAL_DIR, \"saarland.eval\")\n",
    "EVAL_AMOUNTS = 10_000\n",
    "print(MLP_METHODS, \"with\", MLP_LAYERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-purpose",
   "metadata": {},
   "source": [
    "# generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-foster",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create logfile\n",
    "if not os.path.isfile(EVAL_DIR + \"/log.json\"):\n",
    "    os.create(EVAL_DIR + \"/log.json\")\n",
    "# make sure everything compile\n",
    "shell_execute([\"cargo\", \"build\", \"--release\"], EVAL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-handling",
   "metadata": {},
   "source": [
    "## extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-motorcycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMINDER: make sure the correct settings in \"pbfextractor\" are correct\n",
    "OSM_FILES = find_files_ending(\".osm.pbf\", EVAL_DIR)\n",
    "FMI_FILES = out_files(OSM_FILES, \"-latest.osm.pbf\", \".fmi\")\n",
    "print(\"evaluate on\", len(OSM_FILES), \"OSM-file(s)\")\n",
    "for osm_file, fmi_file in zip(OSM_FILES, FMI_FILES):\n",
    "    if not_created_yet(fmi_file, EVAL_DIR):\n",
    "        fmi_longname = fmi_file.replace(\".fmi\", \"-full.txt\")\n",
    "        shell_execute([\"cargo\", \"run\", \"--release\", \"--bin\", \"pbfextractor\", \"--\", osm_file, SRTM_DIR, fmi_longname], EVAL_DIR)\n",
    "        shell_execute([\"cargo\", \"run\", \"--release\", \"--bin\", \"fmi_largest_set\", \"--\", \"-i\", fmi_longname, \"-o\", fmi_file], EVAL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-insured",
   "metadata": {},
   "source": [
    "## eval-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-backing",
   "metadata": {},
   "outputs": [],
   "source": [
    "FMI_FILES = find_files_ending(\".fmi\", EVAL_DIR)\n",
    "EVAL_FILES = out_files(FMI_FILES, \".fmi\", \".eval\")\n",
    "for (fmi_file, eval_file) in zip(FMI_FILES, EVAL_FILES):\n",
    "    if not_created_yet(eval_file, EVAL_DIR):\n",
    "        shell_execute([sys.executable, \"../analysis/generate-eval-file.py\", \"-i\", fmi_file, \"-c\", str(EVAL_AMOUNTS), \"-o\", eval_file], EVAL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-friday",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-palace",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_FILES = list()\n",
    "for fmi_file in find_files_ending(\".fmi\", EVAL_DIR):\n",
    "    for method in MLP_METHODS:\n",
    "        for level in MLP_LAYERS:\n",
    "            PRE_FILES.append([fmi_file, fmi_file.replace(\".fmi\", \"\") + \"-\",method , \"-\", \"_\".join(map(str, level)), \".mlp\"])\n",
    "for pre_file_list in PRE_FILES:\n",
    "    fmi_file = pre_file_list[0]\n",
    "    mlp_file = \"\".join(pre_file_list[1:])\n",
    "    method = pre_file_list[2]\n",
    "    level = pre_file_list[4]\n",
    "    if not_created_yet(mlp_file, EVAL_DIR):\n",
    "        levels = level.split(\"_\")\n",
    "        command = [\"cargo\", \"run\", \"--release\", \"--bin\", \"mlp_\" + method, \"--\", \"-f\", fmi_file, \"-o\", mlp_file, \"-p\"]\n",
    "        for level_index in range(len(levels)):\n",
    "            if method == \"merge\":\n",
    "                value = math.prod(map(int, levels[:(level_index + 1)]))\n",
    "            else:\n",
    "                value = levels[level_index]\n",
    "            command.append(str(value))\n",
    "        shell_execute(command, EVAL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "central-planner",
   "metadata": {},
   "source": [
    "# pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-palestine",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = dict()\n",
    "for fmi_file in find_files_ending(\".fmi\", EVAL_DIR):\n",
    "    for method in MLP_METHODS:\n",
    "        for level in MLP_LAYERS:\n",
    "            combinations[(fmi_file, method, \"_\".join(map(str, level)))] = {\"fmi_file\": fmi_file, \"mlp_file\": fmi_file.replace(\".fmi\", \"\") + \"-\" + method + \"-\" + \"_\".join(map(str, level)) + \".mlp\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-ideal",
   "metadata": {},
   "source": [
    "## mlp-csv-export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-sessions",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ((fmi_file, method, partitions), inputs) in combinations.items():\n",
    "    output = inputs[\"mlp_file\"].replace(\".mlp\", \".csv\")\n",
    "    if not_created_yet(output, EVAL_DIR):\n",
    "        shell_execute([sys.executable, \"../analysis/fmi+mlp_csv-export.py\", \"-f\", inputs[\"fmi_file\"], \"-m\", inputs[\"mlp_file\"], \"-o\", output], EVAL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "under-preserve",
   "metadata": {},
   "source": [
    "## precalculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-vancouver",
   "metadata": {},
   "outputs": [],
   "source": [
    "FMI_FILES = find_files_ending(\".fmi\", EVAL_DIR)\n",
    "MLP_FILES = find_files_ending(\".mlp\", EVAL_DIR)\n",
    "\n",
    "for mlp_file in MLP_FILES:\n",
    "    # get fmi-filename and check if it exists\n",
    "    fmi_file = \"-\".join(mlp_file.split(\"-\")[:-2]) + \".fmi\"\n",
    "    if fmi_file in FMI_FILES:\n",
    "        bin_file = mlp_file.replace(\".mlp\", \".bin\")\n",
    "        if not_created_yet(bin_file, EVAL_DIR):\n",
    "            shell_execute([\"cargo\", \"run\", \"--bin\", \"prp_pre\", \"--release\", \"--\", \"-f\", fmi_file, \"-m\", mlp_file, \"-o\", bin_file], EVAL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-event",
   "metadata": {},
   "source": [
    "## pch-precalculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "FMI_FILES = find_files_ending(\".fmi\", EVAL_DIR)\n",
    "MLP_FILES = find_files_ending(\".mlp\", EVAL_DIR)\n",
    "\n",
    "for mlp_file in find_files_ending(\".mlp\", EVAL_DIR):\n",
    "    fmi_file = \"-\".join(mlp_file.split(\"-\")[:-2]) + \".fmi\"\n",
    "    if fmi_file in FMI_FILES:\n",
    "        with open(fmi_file) as csvfile:\n",
    "            fmireader = csv.reader(csvfile, delimiter=' ')\n",
    "            tmp = next(fmireader)\n",
    "            while len(tmp) == 0 or tmp[0].startswith(\"#\"):\n",
    "                tmp = next(fmireader)\n",
    "            amount_nodes_fmi = int(next(fmireader)[0])\n",
    "        csv_file = mlp_file.replace(\".mlp\", \".csv\")\n",
    "        df = pd.read_csv(csv_file)\n",
    "        contracted_nodes = sum(df.highest_diff.value_counts().loc[1:])\n",
    "        bin_file = mlp_file.replace(\".mlp\", \"-pch.bin\")\n",
    "        percentage = 1 - (contracted_nodes / amount_nodes_fmi)\n",
    "        if not_created_yet(bin_file, EVAL_DIR):\n",
    "            shell_execute([\"cargo\", \"run\", \"--bin\", \"prp_pre\", \"--release\", \"--\", \"-f\", fmi_file, \"-p\", str(percentage), \"-o\", bin_file], EVAL_DIR)\n",
    "    else:\n",
    "        raise SystemExit(\"no compatible fmi-file found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-barcelona",
   "metadata": {},
   "source": [
    "## evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-combining",
   "metadata": {},
   "outputs": [],
   "source": [
    "BIN_FILES = find_files_ending(\".bin\", EVAL_DIR)\n",
    "UNIQUE_BIN_FILES = set([\"-\".join(f.split(\"-\")[:-2]) for f in BIN_FILES])\n",
    "CORE_BIN_FILES = list()\n",
    "for unique_bin_file in UNIQUE_BIN_FILES:\n",
    "    for bin_file in BIN_FILES:\n",
    "        if bin_file.startswith(unique_bin_file):\n",
    "            CORE_BIN_FILES.append(bin_file)\n",
    "            break\n",
    "for method in QUERY_METHODS:\n",
    "    if method == \"normal\" or method == \"bi\":\n",
    "        for file in CORE_BIN_FILES:\n",
    "            out_file = file\n",
    "            for mlp_method in MLP_METHODS:\n",
    "                tmp = \"-\" + mlp_method\n",
    "                if out_file.find(tmp) != -1:\n",
    "                    out_file = out_file[:out_file.index(tmp)]\n",
    "            time_file = out_file + \"-\"+ method + \"-time.json\"\n",
    "            if not_created_yet(time_file, EVAL_DIR):\n",
    "                shell_execute([\"cargo\", \"run\", \"--bin\", \"prp_eval\", \"--release\", \"--\", \"-f\", file, \"-e\", EVAL_FILE, \"-x\", time_file, \"-m\", method, \"-t\", \"time\"], EVAL_DIR)\n",
    "            count_file = out_file + \"-\"+ method + \"-count.json\"\n",
    "            if not_created_yet(count_file, EVAL_DIR):\n",
    "                shell_execute([\"cargo\", \"run\", \"--bin\", \"prp_eval\", \"--release\", \"--\", \"-f\", file, \"-e\", EVAL_FILE, \"-x\", count_file, \"-m\", method, \"-t\", \"count\"], EVAL_DIR)\n",
    "    else:\n",
    "        for file in BIN_FILES:\n",
    "            if file.endswith(\"-pch.bin\"):\n",
    "                if method == \"pch\":\n",
    "                    time_file = file.replace(\".bin\", \"-\"+ method + \"-time.json\")\n",
    "                    if not_created_yet(time_file, EVAL_DIR):\n",
    "                        shell_execute([\"cargo\", \"run\", \"--bin\", \"prp_eval\", \"--release\", \"--\", \"-f\", file, \"-e\", EVAL_FILE, \"-x\", time_file, \"-m\", method, \"-t\", \"time\"], EVAL_DIR)\n",
    "            else:\n",
    "                time_file = file.replace(\".bin\", \"-\"+ method + \"-time.json\")\n",
    "                if not_created_yet(time_file, EVAL_DIR):\n",
    "                    shell_execute([\"cargo\", \"run\", \"--bin\", \"prp_eval\", \"--release\", \"--\", \"-f\", file, \"-e\", EVAL_FILE, \"-x\", time_file, \"-m\", method, \"-t\", \"time\"], EVAL_DIR)\n",
    "                count_file = file.replace(\".bin\", \"-\"+ method + \"-count.json\")\n",
    "                if not_created_yet(count_file, EVAL_DIR):\n",
    "                    shell_execute([\"cargo\", \"run\", \"--bin\", \"prp_eval\", \"--release\", \"--\", \"-f\", file, \"-e\", EVAL_FILE, \"-x\", count_file, \"-m\", method, \"-t\", \"count\"], EVAL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-width",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
