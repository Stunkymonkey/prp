{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-lobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [16, 8]\n",
    "# use LaTeX fonts in the plot\n",
    "matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update({\n",
    "    \"pgf.texsystem\": \"pdflatex\",\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False,\n",
    "})\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-digest",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT = \"level\"\n",
    "EVAL_DIR = \"/home/felix/todo/algohol/level\"\n",
    "MLP_METHODS = [\"merge\"]\n",
    "MLP_LEVELS = [[int(2 ** i)] for i in np.arange(9.0, 11.5, 1.0)]\n",
    "MLP_LEVELS = MLP_LEVELS + [[int(2 ** i), 4] for i in np.arange(9.0, 11.5, 1.0)]\n",
    "MLP_LEVELS = MLP_LEVELS + [[int(2 ** i), 16] for i in np.arange(9.0, 11.5, 1.0)]\n",
    "MLP_LEVELS = MLP_LEVELS + [[int(2 ** i), 4, 4] for i in np.arange(9.0, 11.5, 1.0)]\n",
    "FAST_QUERY_METHODS = [\"pcrp\", \"pch\", \"prp\"]\n",
    "QUERY_METHODS = [\"normal\"] + FAST_QUERY_METHODS\n",
    "AREAS = [\"baden-wuerttemberg\"]\n",
    "SKIP_COUNTS = True\n",
    "print(MLP_METHODS, \"with\", MLP_LEVELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-borough",
   "metadata": {},
   "source": [
    "# Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-equilibrium",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query = pd.DataFrame()\n",
    "for area in AREAS:\n",
    "    for query in QUERY_METHODS:\n",
    "        if query == \"normal\" or query == \"bi\":\n",
    "            tmp = pd.read_json(EVAL_DIR + \"/\" + area + \"-\" + query + \"-time.json\")\n",
    "            tmp[\"Area\"] = area\n",
    "            tmp[\"Query\"] = query\n",
    "            df_query = df_query.append(tmp, ignore_index = True)\n",
    "        else:\n",
    "            for mlp in MLP_METHODS:\n",
    "                for partitions in MLP_LEVELS:\n",
    "                    tmp = pd.read_json(EVAL_DIR + \"/\" + area + \"-\" + mlp + \"-\" + \"_\".join(map(str, partitions)) + \"-\" + query + \"-time.json\")\n",
    "                    tmp[\"Area\"] = area\n",
    "                    tmp[\"Query\"] = query\n",
    "                    tmp[\"Mlp\"] = mlp\n",
    "                    tmp[\"Mlp_partitions\"] = \"_\".join(map(str, partitions))\n",
    "                    df_query = df_query.append(tmp, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-location",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EVAL_DIR + \"/log.json\") as file:\n",
    "    tmp = file.readlines()\n",
    "    log = pd.read_json(\" \".join(tmp), orient='index')\n",
    "# create command string to not match against list\n",
    "log['command_string'] = log['command'].agg(lambda x: ' '.join(map(str, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-tower",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "speedups = list()\n",
    "for area in AREAS:\n",
    "    dijkstra = df_query[(df_query.Query == \"normal\") & (df_query.Area == area)][\"time\"].mean()\n",
    "    bidijkstra = df_query[(df_query.Query == \"bi\") & (df_query.Area == area)][\"time\"].mean()\n",
    "    for mlp in MLP_METHODS:\n",
    "        for partitions in MLP_LEVELS:\n",
    "            row = dict()\n",
    "            for query in FAST_QUERY_METHODS:\n",
    "                tmp = df_query[(df_query.Area == area) & (df_query.Query == query) & (df_query.Mlp == mlp) & (df_query.Mlp_partitions == \"_\".join(map(str, partitions)))]\n",
    "                row[query.upper() + \"-time\"] = ns_to_ms(tmp[\"time\"].mean())\n",
    "                row[query.upper() + \"-speedup\"] = dijkstra / tmp[\"time\"].mean()\n",
    "            \n",
    "            lines = log[(log['command_string'].str.contains(\"prp_pre\")) & (log['command_string'].str.contains(mlp + \"-\" + \"_\".join(map(str, partitions)) + \".bin\"))]\n",
    "            if lines.shape[0] == 0:\n",
    "                continue\n",
    "            line = lines.iloc[-1]\n",
    "            runtime = int(sec_to_min(float(line['time'].replace(\" seconds\", \"\"))))\n",
    "            \n",
    "            pindex = {\"partitions\": \"_\".join(map(str, partitions)), \"pre [min]\": runtime}\n",
    "            speedups.append({**pindex, **row})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-seeking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def special_hacky_sort(x):\n",
    "    splited = x.str.split(\"-\", expand=True)\n",
    "    return pd.DataFrame(splited).astype(float).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-engine",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speedups = pd.DataFrame(speedups)\n",
    "df_speedups['partitions'] = df_speedups['partitions'].str.replace('_','-')\n",
    "assert((df_speedups.groupby([\"partitions\", \"pre [min]\"]).count().all() == 1).iloc[0])\n",
    "df_speedups = df_speedups.groupby([\"partitions\", \"pre [min]\"]).first()\n",
    "df_speedups = df_speedups.sort_values(by=\"partitions\", key=special_hacky_sort)\n",
    "latex = df_speedups.to_latex(float_format=\"{:0.1f}\".format)\n",
    "df_speedups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-smooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixup ugly latex code to have single line header\n",
    "latex_list = latex.splitlines()\n",
    "\n",
    "columns = latex_list[2].split(\"&\")\n",
    "indices = latex_list[3].split(\"&\")\n",
    "\n",
    "latex_list[2] = \"\"\n",
    "for query in FAST_QUERY_METHODS:\n",
    "    latex_list[2] += \"& \\multicolumn{2}{c|}{\" + query.upper() + \"} \"\n",
    "latex_list[2] += \" \\\\\\\\\"\n",
    "# remove last pipe from \"c\"\n",
    "latex_list[2] = \"c\".join(latex_list[2].rsplit(\"c|\", 1))\n",
    "\n",
    "latex_list[3] = \"&\".join(indices[:1] + columns[1:])\n",
    "\n",
    "for query in FAST_QUERY_METHODS:\n",
    "    latex_list[3] = latex_list[3].replace(query.upper() + \"-speedup\", \"speedup\").replace(query.upper() + \"-time\", \"[ms]\")\n",
    "\n",
    "latex_list[0] = latex_list[0].replace('lr', 'l|r', 1)\n",
    "latex_list[0] = latex_list[0].replace('rr', 'rr|', len(FAST_QUERY_METHODS) - 1)\n",
    "\n",
    "latex_list.insert(len(latex_list)-10, '\\midrule')\n",
    "latex_list.insert(len(latex_list)-6, '\\midrule')\n",
    "\n",
    "latex_new = '\\n'.join(latex_list)\n",
    "with open(OUTPUT + \"-speedups.tex\", \"w\") as latex_file:\n",
    "    latex_file.writelines(latex_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-mountain",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
